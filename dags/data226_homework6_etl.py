# -*- coding: utf-8 -*-
"""DATA226_Homework6_ETL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MsRvZAyRzu68kilBCsADCrp89NgkxcTU
"""

from airflow import DAG
from airflow.models import Variable
from airflow.decorators import task
from datetime import datetime
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook
from airflow.operators.trigger_dagrun import TriggerDagRunOperator


def get_snowflake_connection():

    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')
    con = hook.get_conn()
    return con.cursor()


@task
def setup_raw_tables():

    con = get_snowflake_connection()
    con.execute("CREATE OR REPLACE DATABASE USER_DB_JACKAL;")
    con.execute("CREATE OR REPLACE SCHEMA raw;")

    con.execute("""
        CREATE TABLE IF NOT EXISTS USER_DB_JACKAL.raw.user_session_channel (
            userId INT NOT NULL,
            sessionId VARCHAR(32) PRIMARY KEY,
            channel VARCHAR(32) DEFAULT 'direct'
        );
    """)

    con.execute("""
        CREATE TABLE IF NOT EXISTS USER_DB_JACKAL.raw.session_timestamp (
            sessionId VARCHAR(32) PRIMARY KEY,
            ts TIMESTAMP
        );
    """)
    con.close()


@task
def extract():

    con = get_snowflake_connection()
    con.execute("USE DATABASE USER_DB_JACKAL;")
    con.execute("USE SCHEMA raw;")
    con.execute("""
        CREATE OR REPLACE STAGE raw.blob_stage
        url = 's3://s3-geospatial/readonly/'
        file_format = (type = csv, skip_header = 1, field_optionally_enclosed_by = '"');
    """)
    con.close()


@task
def transfer():

    con = get_snowflake_connection()
    con.execute("USE DATABASE USER_DB_JACKAL;")
    con.execute("USE SCHEMA raw;")
    con.execute("""
        COPY INTO raw.user_session_channel
        FROM @raw.blob_stage/user_session_channel.csv;
    """)
    con.close()


@task
def load():
    """Load session_timestamp data from S3 into Snowflake."""
    con = None
    try:
        con = get_snowflake_connection()
        con.execute("BEGIN;")
        con.execute("USE DATABASE USER_DB_JACKAL;")
        con.execute("USE SCHEMA raw;")
        con.execute("""
            COPY INTO raw.session_timestamp
            FROM @raw.blob_stage/session_timestamp.csv;
        """)
        con.execute("COMMIT;")
    except Exception as e:
        if con:
            con.execute("ROLLBACK;")
        raise e
    finally:
        if con:
            con.close()


with DAG(
    dag_id='DATA226_Homework6_ETL',
    catchup=False,
    start_date = datetime(2025, 10, 23),
    tags=['ETL'],
    schedule_interval='0 8 * * *'
) as dag:

    setup = setup_raw_tables()
    extract_stage = extract()
    transfer_data = transfer()
    load_data = load()

    trigger_elt = TriggerDagRunOperator(
        task_id='Trigger_Task',
        trigger_dag_id='BuildELT_CTAS'
    )

    setup >> extract_stage >> transfer_data >> load_data >> trigger_elt